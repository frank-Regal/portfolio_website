<!DOCTYPE html>
<html lang="en">
    <head>
        <!--meta data-->
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="Frank Regal Personal Website" />
        <meta name="keywords" content="portfolio" />
        <meta name="author" content="Frank Regal" />
        <title>Frank Regal - Porfolio</title>
        <!--meta data-->
    
        <!--favicon-img--> 
        <link rel="icon" type="image/png" href="images/fr_logo.png">
        <!--favicon-img-->
    
        <!--main css file-->
        <link rel="stylesheet" href="css/index.css">
        <!--main css file-->
    
        <!--load java script file--> 
        <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.2.6/gsap.min.js"></script>
        <!--load java script file--> 
    </head>
    <body>
        <!--// Page Navigation ========================================================= -->
        <!--navigator-->
        <div id="navigation-content">
            <ul class="navigation-links">
                <li><a href="index.html" data-text="" id="home-link" >HOME</a></li>
                <li><a href="portfolio.html" data-text="" id="blog-link" >PORTFOLIO</a></li>
                <li><a href="https://frankregal.notion.site/Publications-c7dcd42db093466c9ec1e710767217f6" data-text="" id="contact-link" >PUBLICATIONS</a></li>
                <li><a href="about.html" data-text="" id="about-link" >ABOUT</a></li>  
            </ul>
        </div>
      
        <div class="blog">
                <div class="blog-content">
                    <div class="blogs">
                        <a href="https://utnuclearroboticspublic.github.io/ar-affordances/">
                        <div class="img ar-affordance">
                           <img src="images/portfolio/ar_affordance/wheel_robot.png" alt="blog-ten">
                           <div class="blog-date">AR & Robotics</div>
                        </div>
                        <div class="blog-text ar-affordance">
                            <h3>Single Demonstration Task Definition</h3>
                            <p>This robot agnostic learning from demonstration technique enables users to perfrom a single demonstration to 
                                define a manipulation contact-tack for mobile manipulators in unstructured environments.
                                Using a model-based, Affordance Primitive approach (no machine learning techniques), mobile manipulators
                                can navigate, plan, and execute a manipulation (e.g. turn a wheel valve) in any direction with any angle, outside the provided
                                single demonstration limits. Our technique, which takes a user in the field seconds to define, found these demonstrations allow 
                                mobile manipulations to have a 96% completion success rate of prior unknown object manipulations.
                               <br>
                               <br>
                               <br>
                               <span class="project-button">Learn More</span>
                           </p>
                        </div></a>
                    </div>
                    <div class="blogs">
                         <a href="portfolio-pages/augre.html">
                         <div class="img augre">
                            <img src="images/portfolio/augre/augre_cover_small.png" alt="blog-one">
                            <div class="blog-date">AR & Robotics</div>
                         </div>
                         <div class="blog-text augre">
                             <h3>Human-Robot Teaming</h3>
                             <p>Scalable with 50+ robots, this human-robot teaming framework enables users to easily localize, supervise, and command a heterogenous fleet of robots using an augmented reality headset.
                                <br>
                                <br>
                                <br>
                                <span class="project-button">Learn More</span>
                            </p>
                         </div></a>
                     </div>  
                     <div class="blogs">
                        <a href="portfolio-pages/glove_box_ar.html">
                        <div class="img ar-control">
                            <img src="images/portfolio/baxter_ar/kinova_ar_teleop_2.png" alt="blog-two">
                            <div class="blog-date">AR & Robotics</div>
                        </div>
                        <div class="blog-text ar-control">
                            <h3>Dual Arm Teleoperation via AR</h3>
                            <p>This project strives to develop new methods 
                               with augmented reality devices to allow operators to 
                               confidently and effortlessly control dual-arm remote mobile robotic manipulators.
                               <br>
                               <br>
                               <br>
                                <span class="project-button">Learn More</span>
                            </p>
                        </div></a>
                    </div>
                    <div class="blogs">
                        <a href="https://github.com/frank-Regal/cs393r_starter">
                        <div class="img auto-car">
                            <img src="images/portfolio/auto_robots/auto_robots_small.png" alt="blog-three">
                            <div class="blog-date">Robot Autonomy</div>
                        </div>
                        <div class="blog-text auto-car">
                            <h3>Scaled Autonomous Driving Car</h3>
                            <p>For UT Austin's CS 393R Autonomous Robots class with Dr. Joydeep Biswas, my teammate and I created
                                a complete nav-stack for autonomous navigation of an Akermann steering car. Debugging and
                                tuning were performed in simulation. Developed algorithms were deployed on a physical (scaled model)
                                car. Localization performed with a custom 2D-LiDAR particle filter and a custom RRT algorithm was created for planning.
                                <br>
                                <br>
                                <br>
                                <span class="project-button">Learn More</span>
                            </p>
                        </div></a>
                    </div>
                    <div class="blogs">
                        <a href="https://youtu.be/YqiaMAZtBFw">
                            <div class="img">
                                <img src="images/portfolio/kilnbot/kilnbot_cover_small.png" alt="blog-seven">
                                <div class="blog-date kilnbot">Robot Design</div>
                            </div>
                            <div class="blog-text kilnbot">
                                <h3>Magnetic Inspection Robot</h3>
                                <p> Tasked with creating an alternative
                                    method to inspect boiler tube walls for corrosion to eliminate the need of
                                    a human to enter into a hazardous environment, I developed a modular, wirelessly controlled, 3D printed, magnetic inspection crawler from the ground up .
                                    Chain driven by two DC motors, the crawler was able to crawl up and down the 120 ft tall vertical boiler walls. 
                                    Dished magnetic wheels were created to adhere and align itself to the tubes in focus. The entire crawler
                                    was developed in house and cost just under $2,000 for total R&D
                                    <br>
                                    <br>
                                    <br>
                                    <span class="project-button">Learn More</span>
                                </p>
                            </div></a>
                    </div>
                    <div class="blogs">
                        <a href="https://docs.google.com/presentation/d/1lDvpG_wKVkKxDGf0cAsa3iIihvhOZtIM/edit?usp=sharing&ouid=101661046954650984360&rtpof=true&sd=true">
                            <div class="img">
                                <img src="images/portfolio/asbr_robots/asbr_cover_small.png" alt="blog-six">
                                <div class="blog-date motion-planning">Robot Control</div>
                            </div>
                            <div class="blog-text motion-planning">
                                <h3>Motion Planning & Control</h3>
                                <p>For UT Austin's ME 397 Algorithms for Sensor Based Robots class with Dr. Farshid Alambeigi, 
                                    my teammate and I created algorithms to control a Kuka Quantec 6DOF robotic manipulator.
                                    We used skrew theory to model and control the arm. At the end of the class we were able to
                                    control and plan trajectories for robotic manipulators.
                                    Impedence, admittance, hand-to-eye calibration, hand-eye calibration, virtual fixtures, point-cloud registration, 
                                    pivot calibration algorithms and more were all developed from scratch.
                                    <br>
                                    <br>
                                    <br>
                                    <span class="project-button">Learn More</span>
                                </p>
                            </div></a>
                    </div>
                    <div class="blogs">
                        <a href="portfolio-pages/quick_release.html">
                        <div class="img ar-affordance">
                           <img src="images/portfolio/quick_release/quick_release.png" alt="blog-eleven">
                           <div class="blog-date">Mechanism Design</div>
                        </div>
                        <div class="blog-text ar-affordance">
                            <h3>Quick Release Four-Bar Mechanism</h3>
                            <p>The first prototype of this Quick Release Mechanism was designed to aid researchers in the computer science department 
                                at UT Austin attempting to perform the water bottle flip challenge with a robotic arm. 
                                To perform this challenge an end effector needs to have a quick 
                                release mechanism to rapidly release the water bottle from the robotic gripper at the right time. 
                                My partner and I worked to develop a linear translation mechanism that can slowly close (clockwise drive) and rapidly 
                                open (counter-clockwise drive) via a DC motor that would be easily intergratable on a robotic arm.
                               <br>
                               <br>
                               <br>
                               <span class="project-button">Learn More</span>
                           </p>
                        </div></a>
                    </div>        
                    <div class="blogs">
                        <a href="https://drive.google.com/file/d/1r8UXWziQ_Ku1-LZGoyn3_m7jvFbt2HFR/view?usp=sharing">
                            <div class="img haptics">
                                <img src="images/portfolio/haptics_project/haptics_final_design_small.png" alt="blog-four">
                                <div class="blog-date">AR & Robotics</div>
                            </div>
                            <div class="blog-text haptics">
                                <h3>Rapid Item Identification w/ Haptics</h3>
                                <p>For UT Austin's ME 397 Haptics and Teleoperated Systems class with Dr. Ann Fey, my team
                                    and I developed a vibro-tactile haptic device that mounts to the HoloLens 2. The 
                                    device provided sequential vibrations to the users head to help locate robots and 
                                    other items of interest faster in their environment. Development was done with 
                                    Unreal Engine 4, C++, Raspberry-Pi, and a HoloLens 2.
                                    <br>
                                    <br>
                                    <br>
                                    <span class="project-button">Learn More</span>
                                </p>
                            </div></a>
                    </div>   
                    <div class="blogs">
                        <a href="https://drive.google.com/file/d/1r2AIZJUsWhH48wvF9f3dn0MFkfdKZQre/view?usp=sharing">
                            <div class="img">
                                <img src="images/portfolio/digital_control/digital_control_cover_small.png" alt="blog-five">
                                <div class="blog-date robot-latency">Robot Control</div>
                            </div>
                            <div class="blog-text robot-latency">
                                <h3>Robotic Latency Compensation</h3>
                                <p> For UT Austin's ME 397 Digital Controls class with 
                                    Dr. Dongmei "Maggie" Chen, my team and I created a predictive digital control to compensate
                                    for latency found in a specific AR human-robot teaming application (AugRE) that we built in
                                    my lab (NRG). We used advanced control theory to apply a few different techniques such as 
                                    lead compensators, pole placement, linear quadratic regulators (LQR), and Smith predictors to 
                                    compensate the system for both constant and variable delays over a network.
                                    <br>
                                    <br>
                                    <br>
                                    <span class="project-button">Learn More</span>
                                </p>
                            </div></a>
                    </div>   
                    <div class="blogs">
                        <a href="https://drive.google.com/file/d/1rarkUE_f2UhcwClF42Z5uRYrRQL4c59B/view?usp=sharing">
                            <div class="img">
                                <img src="images/portfolio/dracos/dracos_cover_small.png" alt="blog-eight">
                                <div class="blog-date senior-design">AR & Robotics</div>
                            </div>
                            <div class="blog-text senior-design">
                                <h3>AR Scanning and Mapping</h3>
                                <p>For my capstone at Drexel University, my team and I developed
                                    an AR tool to help construction workers easily map, scan, and 
                                    superimpose building models on a spatially mapped environment. The DRACOS system integrated a HoloLens 1 AR device 
                                    with a custom DJI F450 drone. The system allowed the user on the job to deploy a drone and interact
                                    with a 3D model of the physical job site. The HoloLens 1 applictaion allowed the user to import and overlay any 3D models into the application.
                                    <br>
                                    <br>
                                    <br>
                                    <span class="project-button">Learn More</span>
                                </p>
                            </div></a>
                    </div>   
                    <div class="blogs">
                        <a href="https://drive.google.com/file/d/1svQTxcwqArXjck7zESCHhT93I6uJxzH7/view?usp=sharing">
                            <div class="img">
                                <img src="images/portfolio/shadow_arm/robotic_shadow_arm.png" alt="blog-nine">
                                <div class="blog-date shadow-arm">Robot Control</div>
                            </div>
                            <div class="blog-text shadow-arm">
                                <h3>Teleoperation via Shadow Arm</h3>
                                <p> For Drexel University's MEM 455 Robotics class with Dr. James Tangorra, I developed
                                    a scaled down 5R robotic manipulator that was tasked to perform a simulated disaster 
                                    recovery clean-up effort. To control the robot I created a 3D printed shadow arm 
                                    that was a model of the physical robotic arm. The operator teleoped the real robotic
                                    arm by using the shadow arm that mapped potentiometer readings at each joint to physical joint
                                    positions of the real arm to perform the clean-up task.
                                    <br>
                                    <br>
                                    <br>
                                    <span class="project-button">Learn More</span>
                                </p>
                            </div></a>
                    </div> 
                </div>
                <div class="footer">
                    <div class="footer-text">
                        Last Updated July 2022 By Frank Regal 
                        <span class="footer-image">
                            Made In America<img src="images/united-states.png" height="24px">
                        </span> 
                    </div>
                </div>
        </div><!--blog--end-->

    <!--division scripts-->
    <script src="js/jquery.min.js"></script>
    <script src="js/particles.js"></script>
    <script src="js/particles.min.js"></script>
    <script src="js/index.js"></script>
    <!--divisiion scripts-->

    </body>
</html>